{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Script for UEBA Risk Scoring\n",
    "This script prepares the dataset for model training by handling missing values, encoding categorical columns, scaling features, and saving the preprocessing encoders. The encoders are saved as .pkl files, allowing for reusage of them consistently during model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r'C:\\Users\\USER\\UEBA_Project\\risk_scoring\\data\\raw\\train_data.csv'\n",
    "processed_data_path = r'C:\\Users\\USER\\UEBA_Project\\risk_scoring\\data\\processed'\n",
    "os.makedirs(processed_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the preprocessed dataset with target:\n",
      "   id  account  group   IP   url      port      vlan  switchIP      hour  \\\n",
      "0   1      113      1   18   216 -1.106597 -1.030881        44  0.156337   \n",
      "1   2      113      1  101   157 -1.472159 -1.030881        91  0.156337   \n",
      "2   3      113      1   81   373  0.036209 -1.030881        44 -0.078513   \n",
      "3   4      113      1   39  1135 -0.815599 -1.030881       102  0.391186   \n",
      "4   5      113      1   77    57  1.092160 -1.030881        92 -0.078513   \n",
      "\n",
      "   day_of_week     month     ret  \n",
      "0    -0.497079  0.997434  0.1149  \n",
      "1    -1.498123  0.997434  0.1801  \n",
      "2    -0.997601  0.997434  0.3690  \n",
      "3    -0.497079 -0.999262  0.1532  \n",
      "4     1.505010  0.997434  0.1449  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "file_path = r'C:\\Users\\USER\\UEBA_Project\\risk_scoring\\data\\raw\\train_data.csv'\n",
    "processed_data_path = r'C:\\Users\\USER\\UEBA_Project\\risk_scoring\\data\\processed'\n",
    "os.makedirs(processed_data_path, exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Convert the 'time' column to datetime format\n",
    "data['time'] = pd.to_datetime(data['time'], errors='coerce')\n",
    "\n",
    "# Separate 'ret' as the target variable\n",
    "target = data['ret']\n",
    "\n",
    "# Fill missing values for other columns if any\n",
    "data.fillna({\n",
    "    'account': 'Unknown',\n",
    "    'group': 'Unknown',\n",
    "    'IP': '0.0.0.0',\n",
    "    'url': 'unknown',\n",
    "    'port': data['port'].mode()[0],\n",
    "    'vlan': data['vlan'].mode()[0],\n",
    "    'switchIP': '0.0.0.0'\n",
    "}, inplace=True)\n",
    "\n",
    "# Extract useful time-based features\n",
    "data['hour'] = data['time'].dt.hour\n",
    "data['day_of_week'] = data['time'].dt.dayofweek\n",
    "data['month'] = data['time'].dt.month\n",
    "\n",
    "# Drop the original 'time' and 'ret' columns\n",
    "data.drop(columns=['time', 'ret'], inplace=True)\n",
    "\n",
    "# Initialize LabelEncoders for categorical columns\n",
    "label_encoders = {}\n",
    "categorical_columns = ['account', 'group', 'IP', 'url', 'switchIP']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "    # Save each encoder for future use\n",
    "    joblib.dump(le, os.path.join(processed_data_path, f'{col}_encoder.pkl'))\n",
    "\n",
    "# Standardize numerical columns (excluding 'ret')\n",
    "numerical_columns = ['port', 'vlan', 'hour', 'day_of_week', 'month']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, os.path.join(processed_data_path, 'scaler.pkl'))\n",
    "\n",
    "# Combine processed features and target for model training\n",
    "processed_data = data.copy()\n",
    "processed_data['ret'] = target  # Add 'ret' as the target column\n",
    "\n",
    "# Save the processed data and target separately\n",
    "processed_data.to_csv(os.path.join(processed_data_path, 'preprocessed_data_with_target.csv'), index=False)\n",
    "data.to_csv(os.path.join(processed_data_path, 'preprocessed_features.csv'), index=False)\n",
    "target.to_csv(os.path.join(processed_data_path, 'target.csv'), index=False, header=['ret'])\n",
    "\n",
    "# Display the first few rows of the processed dataset\n",
    "print(\"First 5 rows of the preprocessed dataset with target:\")\n",
    "print(processed_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
